"""initial schema

Revision ID: d7c121f65984
Revises: 
Create Date: 2026-02-21 09:47:12.426878

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'd7c121f65984'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('daily_briefs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('date', sa.Date(), nullable=False),
    sa.Column('status', sa.String(length=32), nullable=True),
    sa.Column('total_tokens', sa.Integer(), nullable=True),
    sa.Column('total_cost_usd', sa.Float(), nullable=True),
    sa.Column('idiot_index', sa.Float(), nullable=True),
    sa.Column('generated_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('daily_briefs', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_daily_briefs_date'), ['date'], unique=True)

    op.create_table('daily_cost_summaries',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('date', sa.Date(), nullable=False),
    sa.Column('total_tokens', sa.Integer(), nullable=True),
    sa.Column('total_cost_usd', sa.Float(), nullable=True),
    sa.Column('calls_count', sa.Integer(), nullable=True),
    sa.Column('budget_usd', sa.Float(), nullable=True),
    sa.Column('budget_remaining', sa.Float(), nullable=True),
    sa.Column('idiot_index', sa.Float(), nullable=True),
    sa.Column('breakdown_json', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('date')
    )
    op.create_table('feedback_actions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('action_type', sa.String(length=32), nullable=False),
    sa.Column('target_type', sa.String(length=32), nullable=False),
    sa.Column('target_id', sa.Integer(), nullable=False),
    sa.Column('metadata_json', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('feedback_actions', schema=None) as batch_op:
        batch_op.create_index('ix_feedback_action_date', ['action_type', 'created_at'], unique=False)
        batch_op.create_index('ix_feedback_target', ['target_type', 'target_id'], unique=False)

    op.create_table('market_snapshots',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('symbol', sa.String(length=32), nullable=False),
    sa.Column('name', sa.String(length=128), nullable=True),
    sa.Column('price', sa.Float(), nullable=True),
    sa.Column('change_pct', sa.Float(), nullable=True),
    sa.Column('change_abs', sa.Float(), nullable=True),
    sa.Column('volume', sa.BigInteger(), nullable=True),
    sa.Column('snapshot_date', sa.Date(), nullable=False),
    sa.Column('fetched_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('market_snapshots', schema=None) as batch_op:
        batch_op.create_index('ix_market_symbol_date', ['symbol', 'snapshot_date'], unique=False)

    op.create_table('sources',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=256), nullable=False),
    sa.Column('url', sa.String(length=2048), nullable=False),
    sa.Column('feed_type', sa.String(length=32), nullable=True),
    sa.Column('section', sa.String(length=64), nullable=False),
    sa.Column('region', sa.String(length=32), nullable=True),
    sa.Column('bias_label', sa.String(length=16), nullable=True),
    sa.Column('trust_score', sa.Integer(), nullable=True),
    sa.Column('source_type', sa.String(length=32), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('fetch_interval_min', sa.Integer(), nullable=True),
    sa.Column('last_fetched_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('url')
    )
    with op.batch_alter_table('sources', schema=None) as batch_op:
        batch_op.create_index('ix_sources_section_active', ['section', 'is_active'], unique=False)

    op.create_table('tracked_topics',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=256), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name')
    )
    op.create_table('user_preferences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('key', sa.String(length=128), nullable=False),
    sa.Column('value_json', sa.JSON(), nullable=False),
    sa.Column('is_persistent', sa.Boolean(), nullable=True),
    sa.Column('ttl_days', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('key')
    )
    op.create_table('weather_cache',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('location_name', sa.String(length=128), nullable=False),
    sa.Column('latitude', sa.Float(), nullable=False),
    sa.Column('longitude', sa.Float(), nullable=False),
    sa.Column('date', sa.Date(), nullable=False),
    sa.Column('data_json', sa.JSON(), nullable=False),
    sa.Column('fetched_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('location_name', 'date', name='uq_weather_location_date')
    )
    op.create_table('articles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('source_id', sa.Integer(), nullable=False),
    sa.Column('url', sa.String(length=2048), nullable=False),
    sa.Column('title', sa.String(length=1024), nullable=True),
    sa.Column('raw_html', sa.Text(), nullable=True),
    sa.Column('extracted_text', sa.Text(), nullable=True),
    sa.Column('summary', sa.Text(), nullable=True),
    sa.Column('og_image_url', sa.String(length=2048), nullable=True),
    sa.Column('author', sa.String(length=256), nullable=True),
    sa.Column('published_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('fetched_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('word_count', sa.Integer(), nullable=True),
    sa.Column('language', sa.String(length=8), nullable=True),
    sa.Column('entities_json', sa.JSON(), nullable=True),
    sa.Column('is_duplicate', sa.Boolean(), nullable=True),
    sa.Column('duplicate_of_id', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['duplicate_of_id'], ['articles.id'], ),
    sa.ForeignKeyConstraint(['source_id'], ['sources.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('url')
    )
    with op.batch_alter_table('articles', schema=None) as batch_op:
        batch_op.create_index('ix_articles_fetched', ['fetched_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_articles_source_id'), ['source_id'], unique=False)
        batch_op.create_index('ix_articles_source_published', ['source_id', 'published_at'], unique=False)

    op.create_table('brief_sections',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('brief_id', sa.Integer(), nullable=False),
    sa.Column('section_type', sa.String(length=64), nullable=False),
    sa.Column('title', sa.String(length=256), nullable=True),
    sa.Column('content_json', sa.JSON(), nullable=True),
    sa.Column('content_html', sa.Text(), nullable=True),
    sa.Column('display_order', sa.Integer(), nullable=True),
    sa.Column('tokens_used', sa.Integer(), nullable=True),
    sa.Column('cost_usd', sa.Float(), nullable=True),
    sa.Column('degradation_level', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['brief_id'], ['daily_briefs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('daily_insights',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('text', sa.Text(), nullable=False),
    sa.Column('promoted_to_pref', sa.Boolean(), nullable=True),
    sa.Column('pref_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['pref_id'], ['user_preferences.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('investment_theses',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('date', sa.Date(), nullable=False),
    sa.Column('brief_id', sa.Integer(), nullable=True),
    sa.Column('thesis_text', sa.Text(), nullable=True),
    sa.Column('momentum_signal', sa.JSON(), nullable=True),
    sa.Column('value_signal', sa.JSON(), nullable=True),
    sa.Column('gate_passed', sa.Boolean(), nullable=True),
    sa.Column('supporting_clusters_json', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['brief_id'], ['daily_briefs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('llm_call_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('call_purpose', sa.String(length=128), nullable=False),
    sa.Column('model', sa.String(length=64), nullable=False),
    sa.Column('prompt_tokens', sa.Integer(), nullable=False),
    sa.Column('completion_tokens', sa.Integer(), nullable=False),
    sa.Column('total_tokens', sa.Integer(), nullable=False),
    sa.Column('cost_usd', sa.Float(), nullable=False),
    sa.Column('latency_ms', sa.Integer(), nullable=True),
    sa.Column('section', sa.String(length=64), nullable=True),
    sa.Column('brief_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['brief_id'], ['daily_briefs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('llm_call_logs', schema=None) as batch_op:
        batch_op.create_index('ix_llm_logs_brief', ['brief_id'], unique=False)
        batch_op.create_index('ix_llm_logs_section_date', ['section', 'created_at'], unique=False)

    op.create_table('stories',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('topic_id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=512), nullable=False),
    sa.Column('status', sa.String(length=32), nullable=True),
    sa.Column('first_seen', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('last_updated', sa.DateTime(timezone=True), nullable=True),
    sa.Column('cluster_ids_json', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['topic_id'], ['tracked_topics.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('article_embeddings',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('article_id', sa.Integer(), nullable=False),
    sa.Column('simhash', sa.BigInteger(), nullable=False),
    sa.Column('embedding_blob', sa.LargeBinary(), nullable=True),
    sa.Column('embedding_model', sa.String(length=64), nullable=True),
    sa.Column('embedding_dim', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['article_id'], ['articles.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('article_id')
    )
    with op.batch_alter_table('article_embeddings', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_article_embeddings_simhash'), ['simhash'], unique=False)

    op.create_table('claim_ledger',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('story_id', sa.Integer(), nullable=True),
    sa.Column('claim_text', sa.Text(), nullable=False),
    sa.Column('source_id', sa.Integer(), nullable=True),
    sa.Column('article_id', sa.Integer(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=32), nullable=True),
    sa.Column('contradicts_claim_id', sa.Integer(), nullable=True),
    sa.Column('evidence_json', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['article_id'], ['articles.id'], ),
    sa.ForeignKeyConstraint(['contradicts_claim_id'], ['claim_ledger.id'], ),
    sa.ForeignKeyConstraint(['source_id'], ['sources.id'], ),
    sa.ForeignKeyConstraint(['story_id'], ['stories.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('claim_ledger', schema=None) as batch_op:
        batch_op.create_index('ix_claims_article', ['article_id'], unique=False)
        batch_op.create_index('ix_claims_story_status', ['story_id', 'status'], unique=False)

    op.create_table('clusters',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('section', sa.String(length=64), nullable=False),
    sa.Column('label', sa.String(length=512), nullable=True),
    sa.Column('summary', sa.Text(), nullable=True),
    sa.Column('representative_article_id', sa.Integer(), nullable=True),
    sa.Column('article_count', sa.Integer(), nullable=True),
    sa.Column('avg_trust_score', sa.Float(), nullable=True),
    sa.Column('rank_score', sa.Float(), nullable=True),
    sa.Column('brief_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('date', sa.Date(), nullable=False),
    sa.ForeignKeyConstraint(['brief_id'], ['daily_briefs.id'], ),
    sa.ForeignKeyConstraint(['representative_article_id'], ['articles.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('clusters', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_clusters_date'), ['date'], unique=False)
        batch_op.create_index('ix_clusters_section_date_rank', ['section', 'date', 'rank_score'], unique=False)

    op.create_table('cluster_memberships',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('cluster_id', sa.Integer(), nullable=False),
    sa.Column('article_id', sa.Integer(), nullable=False),
    sa.Column('similarity', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['article_id'], ['articles.id'], ),
    sa.ForeignKeyConstraint(['cluster_id'], ['clusters.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('cluster_id', 'article_id', name='uq_cluster_article')
    )
    op.create_table('events',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('story_id', sa.Integer(), nullable=False),
    sa.Column('cluster_id', sa.Integer(), nullable=True),
    sa.Column('description', sa.Text(), nullable=False),
    sa.Column('event_date', sa.DateTime(timezone=True), nullable=True),
    sa.Column('source_urls_json', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['cluster_id'], ['clusters.id'], ),
    sa.ForeignKeyConstraint(['story_id'], ['stories.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('market_drivers',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('snapshot_id', sa.Integer(), nullable=True),
    sa.Column('cluster_id', sa.Integer(), nullable=True),
    sa.Column('driver_text', sa.Text(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('date', sa.Date(), nullable=False),
    sa.ForeignKeyConstraint(['cluster_id'], ['clusters.id'], ),
    sa.ForeignKeyConstraint(['snapshot_id'], ['market_snapshots.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('market_drivers')
    op.drop_table('events')
    op.drop_table('cluster_memberships')
    with op.batch_alter_table('clusters', schema=None) as batch_op:
        batch_op.drop_index('ix_clusters_section_date_rank')
        batch_op.drop_index(batch_op.f('ix_clusters_date'))

    op.drop_table('clusters')
    with op.batch_alter_table('claim_ledger', schema=None) as batch_op:
        batch_op.drop_index('ix_claims_story_status')
        batch_op.drop_index('ix_claims_article')

    op.drop_table('claim_ledger')
    with op.batch_alter_table('article_embeddings', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_article_embeddings_simhash'))

    op.drop_table('article_embeddings')
    op.drop_table('stories')
    with op.batch_alter_table('llm_call_logs', schema=None) as batch_op:
        batch_op.drop_index('ix_llm_logs_section_date')
        batch_op.drop_index('ix_llm_logs_brief')

    op.drop_table('llm_call_logs')
    op.drop_table('investment_theses')
    op.drop_table('daily_insights')
    op.drop_table('brief_sections')
    with op.batch_alter_table('articles', schema=None) as batch_op:
        batch_op.drop_index('ix_articles_source_published')
        batch_op.drop_index(batch_op.f('ix_articles_source_id'))
        batch_op.drop_index('ix_articles_fetched')

    op.drop_table('articles')
    op.drop_table('weather_cache')
    op.drop_table('user_preferences')
    op.drop_table('tracked_topics')
    with op.batch_alter_table('sources', schema=None) as batch_op:
        batch_op.drop_index('ix_sources_section_active')

    op.drop_table('sources')
    with op.batch_alter_table('market_snapshots', schema=None) as batch_op:
        batch_op.drop_index('ix_market_symbol_date')

    op.drop_table('market_snapshots')
    with op.batch_alter_table('feedback_actions', schema=None) as batch_op:
        batch_op.drop_index('ix_feedback_target')
        batch_op.drop_index('ix_feedback_action_date')

    op.drop_table('feedback_actions')
    op.drop_table('daily_cost_summaries')
    with op.batch_alter_table('daily_briefs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_daily_briefs_date'))

    op.drop_table('daily_briefs')
    # ### end Alembic commands ###
